{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the keras status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils # let label transit to 0ne-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # grouping the minst's data to train and test group\n",
    "\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  #there are 60000 train images, and the image is in 28 x 28 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape) # the corresponging number with respect to 60000 images is 60000 as predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # create linear implementing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu')) # add input layer and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=10, kernel_initializer='normal', activation='softmax')) # add output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # Compilation: Choose loss function, optimization method and effectiveness measurement method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TrainOneHot = np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TestOneHot = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2D = X_train.reshape(60000, 28*28).astype('float32')\n",
    "X_test_2D = X_test.reshape(10000, 28*28).astype('float32') # 2D-1D\n",
    "X_train_2D.shape,X_test_2D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) #there are 10000 test images, and the image is in 28 x 28 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_2D:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test_2D: \",X_test_2D.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_2d (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print('X_train_2d',X_train_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Train_norm = X_train_2D/255\n",
    "x_Test_norm = X_test_2D/255 # important process, nomalize the gray level of input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 991us/step - loss: 2.3650 - accuracy: 0.0857\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_Test_norm, y_TestOneHot) #before traing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Info] Accuracy of testing data = 8.6%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict the number before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('E:/computer vision/number/5.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = (28, 28)\n",
    "img = cv2.resize(img, crop_size, interpolation = cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('My Image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n"
     ]
    }
   ],
   "source": [
    "img_2D = img.reshape(1,28*28).astype('float32')\n",
    "img_norm=img_2D/255\n",
    "img = img_norm\n",
    "# predictions = model.predict_classes(img) \n",
    "predictions = np.argmax(model.predict(img),axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we are going to train the data to get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 - 1s - loss: 0.7912 - accuracy: 0.8094 - val_loss: 0.3173 - val_accuracy: 0.9113 - 947ms/epoch - 16ms/step\n",
      "Epoch 2/100\n",
      "60/60 - 0s - loss: 0.2961 - accuracy: 0.9181 - val_loss: 0.2468 - val_accuracy: 0.9311 - 485ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "60/60 - 0s - loss: 0.2330 - accuracy: 0.9345 - val_loss: 0.2032 - val_accuracy: 0.9444 - 421ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "60/60 - 0s - loss: 0.1918 - accuracy: 0.9454 - val_loss: 0.1766 - val_accuracy: 0.9520 - 441ms/epoch - 7ms/step\n",
      "Epoch 5/100\n",
      "60/60 - 0s - loss: 0.1627 - accuracy: 0.9539 - val_loss: 0.1567 - val_accuracy: 0.9564 - 424ms/epoch - 7ms/step\n",
      "Epoch 6/100\n",
      "60/60 - 0s - loss: 0.1404 - accuracy: 0.9600 - val_loss: 0.1429 - val_accuracy: 0.9594 - 449ms/epoch - 7ms/step\n",
      "Epoch 7/100\n",
      "60/60 - 0s - loss: 0.1225 - accuracy: 0.9655 - val_loss: 0.1335 - val_accuracy: 0.9627 - 432ms/epoch - 7ms/step\n",
      "Epoch 8/100\n",
      "60/60 - 0s - loss: 0.1083 - accuracy: 0.9704 - val_loss: 0.1247 - val_accuracy: 0.9648 - 464ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "60/60 - 0s - loss: 0.0960 - accuracy: 0.9744 - val_loss: 0.1160 - val_accuracy: 0.9672 - 431ms/epoch - 7ms/step\n",
      "Epoch 10/100\n",
      "60/60 - 0s - loss: 0.0869 - accuracy: 0.9763 - val_loss: 0.1093 - val_accuracy: 0.9691 - 442ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "60/60 - 0s - loss: 0.0776 - accuracy: 0.9793 - val_loss: 0.1067 - val_accuracy: 0.9693 - 422ms/epoch - 7ms/step\n",
      "Epoch 12/100\n",
      "60/60 - 0s - loss: 0.0703 - accuracy: 0.9810 - val_loss: 0.1016 - val_accuracy: 0.9696 - 430ms/epoch - 7ms/step\n",
      "Epoch 13/100\n",
      "60/60 - 0s - loss: 0.0639 - accuracy: 0.9823 - val_loss: 0.0992 - val_accuracy: 0.9707 - 448ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "60/60 - 0s - loss: 0.0583 - accuracy: 0.9847 - val_loss: 0.0957 - val_accuracy: 0.9713 - 440ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "60/60 - 0s - loss: 0.0528 - accuracy: 0.9864 - val_loss: 0.0949 - val_accuracy: 0.9716 - 427ms/epoch - 7ms/step\n",
      "Epoch 16/100\n",
      "60/60 - 0s - loss: 0.0481 - accuracy: 0.9878 - val_loss: 0.0919 - val_accuracy: 0.9722 - 399ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "60/60 - 0s - loss: 0.0440 - accuracy: 0.9892 - val_loss: 0.0912 - val_accuracy: 0.9730 - 395ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "60/60 - 0s - loss: 0.0402 - accuracy: 0.9902 - val_loss: 0.0872 - val_accuracy: 0.9737 - 421ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "60/60 - 0s - loss: 0.0371 - accuracy: 0.9911 - val_loss: 0.0858 - val_accuracy: 0.9746 - 386ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "60/60 - 0s - loss: 0.0333 - accuracy: 0.9923 - val_loss: 0.0849 - val_accuracy: 0.9742 - 414ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "60/60 - 0s - loss: 0.0312 - accuracy: 0.9933 - val_loss: 0.0861 - val_accuracy: 0.9741 - 386ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "60/60 - 0s - loss: 0.0286 - accuracy: 0.9942 - val_loss: 0.0830 - val_accuracy: 0.9742 - 390ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "60/60 - 0s - loss: 0.0259 - accuracy: 0.9948 - val_loss: 0.0828 - val_accuracy: 0.9760 - 398ms/epoch - 7ms/step\n",
      "Epoch 24/100\n",
      "60/60 - 0s - loss: 0.0243 - accuracy: 0.9953 - val_loss: 0.0823 - val_accuracy: 0.9752 - 385ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "60/60 - 0s - loss: 0.0221 - accuracy: 0.9958 - val_loss: 0.0845 - val_accuracy: 0.9749 - 401ms/epoch - 7ms/step\n",
      "Epoch 26/100\n",
      "60/60 - 0s - loss: 0.0204 - accuracy: 0.9965 - val_loss: 0.0823 - val_accuracy: 0.9750 - 387ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "60/60 - 1s - loss: 0.0188 - accuracy: 0.9971 - val_loss: 0.0805 - val_accuracy: 0.9759 - 672ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "60/60 - 0s - loss: 0.0172 - accuracy: 0.9973 - val_loss: 0.0830 - val_accuracy: 0.9754 - 389ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "60/60 - 0s - loss: 0.0161 - accuracy: 0.9978 - val_loss: 0.0814 - val_accuracy: 0.9760 - 399ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "60/60 - 0s - loss: 0.0147 - accuracy: 0.9980 - val_loss: 0.0837 - val_accuracy: 0.9760 - 389ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "60/60 - 0s - loss: 0.0136 - accuracy: 0.9984 - val_loss: 0.0822 - val_accuracy: 0.9764 - 402ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "60/60 - 0s - loss: 0.0125 - accuracy: 0.9986 - val_loss: 0.0815 - val_accuracy: 0.9768 - 386ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "60/60 - 0s - loss: 0.0119 - accuracy: 0.9986 - val_loss: 0.0825 - val_accuracy: 0.9769 - 398ms/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "60/60 - 0s - loss: 0.0106 - accuracy: 0.9990 - val_loss: 0.0821 - val_accuracy: 0.9768 - 388ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "60/60 - 0s - loss: 0.0099 - accuracy: 0.9992 - val_loss: 0.0822 - val_accuracy: 0.9765 - 402ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "60/60 - 0s - loss: 0.0092 - accuracy: 0.9993 - val_loss: 0.0829 - val_accuracy: 0.9770 - 383ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "60/60 - 0s - loss: 0.0085 - accuracy: 0.9994 - val_loss: 0.0818 - val_accuracy: 0.9769 - 396ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "60/60 - 0s - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.0835 - val_accuracy: 0.9775 - 392ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "60/60 - 0s - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.0831 - val_accuracy: 0.9778 - 399ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "60/60 - 0s - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.0838 - val_accuracy: 0.9772 - 392ms/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "60/60 - 0s - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0852 - val_accuracy: 0.9778 - 398ms/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "60/60 - 0s - loss: 0.0059 - accuracy: 0.9997 - val_loss: 0.0851 - val_accuracy: 0.9773 - 386ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "60/60 - 0s - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.0842 - val_accuracy: 0.9777 - 392ms/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "60/60 - 0s - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.0848 - val_accuracy: 0.9768 - 392ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "60/60 - 0s - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0842 - val_accuracy: 0.9780 - 390ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "60/60 - 0s - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0859 - val_accuracy: 0.9782 - 390ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "60/60 - 0s - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.0857 - val_accuracy: 0.9778 - 391ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "60/60 - 0s - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0870 - val_accuracy: 0.9774 - 393ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "60/60 - 0s - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0856 - val_accuracy: 0.9779 - 385ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "60/60 - 0s - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0860 - val_accuracy: 0.9780 - 406ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "60/60 - 0s - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0875 - val_accuracy: 0.9774 - 386ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "60/60 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9775 - 400ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "60/60 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9778 - 393ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "60/60 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9776 - 402ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "60/60 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9772 - 391ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "60/60 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9779 - 395ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "60/60 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9783 - 399ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "60/60 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9770 - 419ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "60/60 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9777 - 399ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "60/60 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9783 - 413ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "60/60 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9781 - 398ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "60/60 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9775 - 411ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "60/60 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9781 - 402ms/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "60/60 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9782 - 405ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "60/60 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9783 - 415ms/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "60/60 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9778 - 400ms/epoch - 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "60/60 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9775 - 408ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "60/60 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9783 - 403ms/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "60/60 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9781 - 412ms/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "60/60 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9781 - 402ms/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "60/60 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9780 - 406ms/epoch - 7ms/step\n",
      "Epoch 72/100\n",
      "60/60 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9779 - 401ms/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "60/60 - 0s - loss: 9.9804e-04 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9786 - 413ms/epoch - 7ms/step\n",
      "Epoch 74/100\n",
      "60/60 - 1s - loss: 9.6380e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9778 - 636ms/epoch - 11ms/step\n",
      "Epoch 75/100\n",
      "60/60 - 1s - loss: 8.9427e-04 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9786 - 1s/epoch - 19ms/step\n",
      "Epoch 76/100\n",
      "60/60 - 1s - loss: 8.6798e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9780 - 1s/epoch - 17ms/step\n",
      "Epoch 77/100\n",
      "60/60 - 1s - loss: 8.2276e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9783 - 544ms/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "60/60 - 0s - loss: 7.9569e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9782 - 430ms/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "60/60 - 0s - loss: 7.4860e-04 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9779 - 425ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "60/60 - 0s - loss: 7.1949e-04 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9779 - 409ms/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "60/60 - 0s - loss: 6.9807e-04 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9780 - 426ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "60/60 - 0s - loss: 6.6479e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9781 - 405ms/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "60/60 - 0s - loss: 6.3545e-04 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9784 - 410ms/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "60/60 - 0s - loss: 6.0223e-04 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9779 - 403ms/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "60/60 - 0s - loss: 5.8314e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9782 - 421ms/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "60/60 - 0s - loss: 5.6145e-04 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9781 - 396ms/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "60/60 - 1s - loss: 5.3825e-04 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9782 - 585ms/epoch - 10ms/step\n",
      "Epoch 88/100\n",
      "60/60 - 0s - loss: 5.1743e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9785 - 438ms/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "60/60 - 1s - loss: 4.9610e-04 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9781 - 685ms/epoch - 11ms/step\n",
      "Epoch 90/100\n",
      "60/60 - 0s - loss: 4.7406e-04 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9784 - 399ms/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "60/60 - 0s - loss: 4.5258e-04 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9786 - 408ms/epoch - 7ms/step\n",
      "Epoch 92/100\n",
      "60/60 - 0s - loss: 4.4048e-04 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9785 - 407ms/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "60/60 - 0s - loss: 4.2208e-04 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9785 - 408ms/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "60/60 - 0s - loss: 3.9846e-04 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9783 - 399ms/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "60/60 - 0s - loss: 3.8903e-04 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9783 - 423ms/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "60/60 - 0s - loss: 3.7696e-04 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9784 - 407ms/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "60/60 - 0s - loss: 3.5956e-04 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9791 - 402ms/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "60/60 - 0s - loss: 3.4023e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9786 - 405ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "60/60 - 0s - loss: 3.2757e-04 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9787 - 411ms/epoch - 7ms/step\n",
      "Epoch 100/100\n",
      "60/60 - 1s - loss: 3.1709e-04 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9787 - 661ms/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x=x_Train_norm, y=y_TrainOneHot, validation_split=0.2, epochs=100, batch_size=800, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 872us/step - loss: 0.0944 - accuracy: 0.9786\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_Test_norm, y_TestOneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## after trainging, the accuracy was increased from 0.15 to  0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Info] Accuracy of testing data = 97.9%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('E:/computer vision/number/5.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = (28, 28)\n",
    "img = cv2.resize(img, crop_size, interpolation = cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "img_2D = img.reshape(1,28*28).astype('float32')\n",
    "img_norm=img_2D/255\n",
    "img = img_norm\n",
    "# predictions = model.predict_classes(img) #\n",
    "predictions = np.argmax(model.predict(img),axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('E:/computer vision/number/1.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = (28, 28)\n",
    "img = cv2.resize(img, crop_size, interpolation = cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2D = img.reshape(1,28*28).astype('float32')\n",
    "img_norm=img_2D/255\n",
    "img = img_norm\n",
    "predictions = model.predict_classes(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
